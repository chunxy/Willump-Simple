{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WILLUMP - Demo\n",
    "\n",
    "In this notebook, we'll explain how Willump improves the performance of feature computation in ML inference applications.\n",
    "\n",
    "This version of Willump works specifically on binary classification problems.  It improves performance via _cascades_.  It tries to predict each data input using an approximate model trained on a handful of high-value, low cost features.  For each data input, it returns the approximate prediction if the model's confidence in it is high, but otherwise computes all remaining features and predicts with the original model.  For a more in-depth discussion of Willump, please see [our paper](http://petereliaskraft.net/res/willump.pdf).\n",
    "\n",
    "We're going to be optimizing a specific application, which predicts whether a user of an online music streaming platform will like a song.  The application was adapted from a top finisher in Kaggle's [KKBox Music Recommendation Challenge](https://www.kaggle.com/c/kkbox-music-recommendation-challenge/overview).\n",
    "\n",
    "First, let's import dependencies.  Be sure that the printed working directory is the root directory of the Willump-Simple package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Peter/Documents/GitHub/Willump-Simple\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import redis\n",
    "if (os.getcwd().endswith(\"notebooks\")):\n",
    "    os.chdir(\"..\")\n",
    "sys.path.insert(0, os.path.abspath(\"tests/benchmark_scripts\"))\n",
    "print(os.getcwd())\n",
    "import music_utils\n",
    "from music_utils import get_features_from_redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application precomputes features for different users and songs and stores them in a database, querying the database when making predictions.  It then makes predictions using a boosted trees model.  In this demo, let's store features in Redis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = redis.StrictRedis(host=\"localhost\")\n",
    "train_X, test_X, train_y, test_y = music_utils.load_music_dataset(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willump requires applications to be written in a specific format.  First, they must define functions for model training, prediction, confidence, and scoring.  \n",
    "\n",
    "The training function takes in a vector of training labels and a list of feature vectors and outputs a trained model. \n",
    "\n",
    "The prediction function takes in a model and a list of feature vectors and outputs a vector of predictions.\n",
    "\n",
    "The confidence function takes in a model and a lsit of feature vectors and outputs a vector of the model's confidences in its predictions.\n",
    "\n",
    "The scoring function takes in vectors of predicted and true labels and outputs a score, where higher scores are better.\n",
    "\n",
    "In this application, the training function trains a boosted trees model, the prediction and confidence functions use it to make predictions, and the score function computes an AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_train(y, X_list):\n",
    "    X = pd.concat(X_list, axis=1)\n",
    "    X = X[[f for f in music_utils.FEATURES if f in X.columns]]\n",
    "    model = LGBMClassifier(\n",
    "        n_jobs=1,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=(2 ** 8),\n",
    "        max_depth=15,\n",
    "        metric=\"auc\")\n",
    "    model = model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def music_predict(model, X_list):\n",
    "    X = pd.concat(X_list, axis=1)\n",
    "    X = X[[f for f in music_utils.FEATURES if f in X.columns]]\n",
    "    if len(X) == 0:\n",
    "        return np.zeros(0, dtype=np.float32)\n",
    "    else:\n",
    "        return model.predict(X)\n",
    "\n",
    "\n",
    "def music_confidence(model, X_list):\n",
    "    X = pd.concat(X_list, axis=1)\n",
    "    X = X[[f for f in music_utils.FEATURES if f in X.columns]]\n",
    "    return model.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "def music_score(true_y, pred_y):\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(true_y, pred_y, pos_label=1)\n",
    "    return sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application itself must be writen as a Python function that computes features and then either trains a model or makes predictions.  To make parsing easy, we require that the function be written in [static single assignment form](https://en.wikipedia.org/wiki/Static_single_assignment_form):  each line calls a Python function to compute some feature.  The last line trains a model or makes predictions from these features.\n",
    "\n",
    "Below is our application, written as a Python function. Each line retrieves a different set of features.  The final line trains a model on all of them.\n",
    "\n",
    "The decorator attached to this function is the Willump interface.  It tells Willump to train cascades using this pipeline and model functions.  To train cascades, simply execute the decorated function on a training set and labels; Willump will automatically construct cascades and store their parameters in the train_cascades_params dictionary so they can later be used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from willump.evaluation.willump_executor import willump_execute\n",
    "\n",
    "train_cascades_params = {} # The computed parameters will be stored here.\n",
    "\n",
    "@willump_execute(train_function=music_train,\n",
    "                 predict_function=music_predict,\n",
    "                 confidence_function=music_confidence,\n",
    "                 score_function=music_score,\n",
    "                 train_cascades_params=train_cascades_params)\n",
    "def music_train_pipeline(input_X, input_y):\n",
    "    user_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"features_uf\", db=db)\n",
    "    song_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"features_sf\", db=db)\n",
    "    user_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_msno_25\", name=\"uc_features\", db=db)\n",
    "    song_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_song_id_25\", name=\"sc_features\", db=db)\n",
    "    artist_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_artist_name_25\", name=\"ac_features\", db=db)\n",
    "    user_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"us_features\", db=db)\n",
    "    song_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"ss_features\", db=db)\n",
    "    artist_features = get_features_from_redis(\n",
    "        input_X, column=\"artist_name\", name=\"as_features\", db=db)\n",
    "    genre_features = get_features_from_redis(\n",
    "        input_X, column=\"genre_max\", name=\"gs_features\", db=db)\n",
    "    city_features = get_features_from_redis(\n",
    "        input_X, column=\"city\", name=\"cs_features\", db=db)\n",
    "    ages_features = get_features_from_redis(\n",
    "        input_X, column=\"bd\", name=\"ages_features\", db=db)\n",
    "    language_features = get_features_from_redis(\n",
    "        input_X, column=\"language\", name=\"ls_features\", db=db)\n",
    "    gender_features = get_features_from_redis(\n",
    "        input_X, column=\"gender\", name=\"gender_features\", db=db)\n",
    "    composer_features = get_features_from_redis(\n",
    "        input_X, column=\"composer\", name=\"composer_features\", db=db)\n",
    "    lyrs_features = get_features_from_redis(\n",
    "        input_X, column=\"lyricist\", name=\"lyrs_features\", db=db)\n",
    "    sns_features = get_features_from_redis(\n",
    "        input_X, column=\"source_screen_name\", name=\"sns_features\", db=db)\n",
    "    stabs_features = get_features_from_redis(\n",
    "        input_X, column=\"source_system_tab\", name=\"stabs_features\", db=db)\n",
    "    stypes_features = get_features_from_redis(\n",
    "        input_X, column=\"source_type\", name=\"stypes_features\", db=db)\n",
    "    regs_features = get_features_from_redis(\n",
    "        input_X, column=\"registered_via\", name=\"regs_features\", db=db)\n",
    "    return music_train(input_y,\n",
    "                       [user_latent_features, song_latent_features, user_cluster_features,\n",
    "                        song_cluster_features, artist_cluster_features, user_features,\n",
    "                        song_features, artist_features, genre_features, city_features,\n",
    "                        ages_features, language_features, gender_features,\n",
    "                        composer_features,lyrs_features, sns_features, stabs_features,\n",
    "                        stypes_features, regs_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better explain _how_ Willump works, instead of constructing cascades using the decorator, we will construct them manually, explaining each step of the process.  To construct cascades, we must find a set of high-value, low-cost features from which we can train an approximate model that can make accurate predictions.\n",
    "\n",
    "To do this, we'll first compute all the features used in the pipeline and measure the cost of each--how long each took to compute.  We find that each feature takes the same amount of time to compute, which makes sense as they're all stored in the same server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from willump.evaluation import cascades_construct\n",
    "\n",
    "train_X_features, feature_costs, feature_names = music_utils.compute_features(train_X, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll measure the importance of each feature: how much value it has to the model.  We measure feature importance using [permutation importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html), a model-agnostic metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: user_latent_features      Cost:  1.000 Importance:  0.102\n",
      "Feature: user_cluster_features     Cost:  1.000 Importance:  0.040\n",
      "Feature: song_cluster_features     Cost:  1.000 Importance:  0.039\n",
      "Feature: sns_features              Cost:  1.000 Importance:  0.033\n",
      "Feature: song_latent_features      Cost:  1.000 Importance:  0.023\n",
      "Feature: stabs_features            Cost:  1.000 Importance:  0.016\n",
      "Feature: user_features             Cost:  1.000 Importance:  0.015\n",
      "Feature: artist_cluster_features   Cost:  1.000 Importance:  0.011\n",
      "Feature: stypes_features           Cost:  1.000 Importance:  0.008\n",
      "Feature: regs_features             Cost:  1.000 Importance:  0.007\n",
      "Feature: city_features             Cost:  1.000 Importance:  0.006\n",
      "Feature: genre_features            Cost:  1.000 Importance:  0.005\n",
      "Feature: ages_features             Cost:  1.000 Importance:  0.004\n",
      "Feature: language_features         Cost:  1.000 Importance:  0.002\n",
      "Feature: artist_features           Cost:  1.000 Importance:  0.002\n",
      "Feature: gender_features           Cost:  1.000 Importance:  0.001\n",
      "Feature: composer_features         Cost:  1.000 Importance:  0.000\n",
      "Feature: song_features             Cost:  1.000 Importance: -0.001\n",
      "Feature: lyrs_features             Cost:  1.000 Importance: -0.001\n"
     ]
    }
   ],
   "source": [
    "cascades_train_X, cascades_valid_X, cascades_train_y, cascades_valid_y = \\\n",
    "    cascades_construct.train_test_split(train_X_features, train_y, test_size=0.25, random_state=42)\n",
    "train_set_full_model = music_train(cascades_train_y, cascades_train_X)\n",
    "\n",
    "feature_importances = \\\n",
    "    cascades_construct.calculate_feature_importances(train_set_full_model,\n",
    "                                                     cascades_valid_X, cascades_valid_y,\n",
    "                                                     music_predict, music_score,\n",
    "                                                     feature_names)\n",
    "\n",
    "cascades_construct.pretty_print(feature_importances, feature_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the cost and importance of each feature, let's construct cascades!  To do this, let's pick a feature cost cutoff; for example, half the total feature cost.  We'll construct cascades from the best set of features whose cost is less than that cutoff, defined as the set with maximum feature importance scores.  This is computable by a simple [knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature cost: 19.000  Selected feature cost cutoff: 9.500\n",
      "Selected features:\n",
      "\tuser_latent_features\n",
      "\tsong_latent_features\n",
      "\tuser_cluster_features\n",
      "\tsong_cluster_features\n",
      "\tartist_cluster_features\n",
      "\tuser_features\n",
      "\tsns_features\n",
      "\tstabs_features\n",
      "\tstypes_features\n"
     ]
    }
   ],
   "source": [
    "total_feature_cost = sum(feature_costs.values())\n",
    "cost_cutoff = 0.5 * total_feature_cost\n",
    "selected_indices = cascades_construct.select_features(feature_costs, feature_importances, cost_cutoff)\n",
    "selected_features = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "print(\"Total feature cost: %5.3f  Selected feature cost cutoff: %5.3f\" % (total_feature_cost, cost_cutoff))\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_features:\n",
    "    print(\"\\t%s\" % feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now selected a set of features!  Let's see how well it does.  To construct cascades, we train an approximate model from those features.  We then predict a held-out validation set with that model to compute a confidence threshold; cascades only return approximate predictions if their confidence is above that threshold.  To estimate how much cascades will improve performance, we can average the cost of computing the selected features with the cost of computing all features, weighted by the fraction of data inputs we expect will be approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold: 0.600  Percentage of inputs approximated: 0.818\n",
      "Expected Query Cost = Percent Approximated * Selected Feature Cost +\n",
      "\t\t      Percent Not Approximated * Total Feature Cost\n",
      "\t\t    = 0.818 * 9.000 + 0.182 * 19.000 = 10.823\n",
      "Projected speedup: 1.756\n"
     ]
    }
   ],
   "source": [
    "threshold, fraction_approximated = \\\n",
    "    cascades_construct.calculate_feature_set_performance(cascades_train_X, cascades_train_y, \n",
    "                                                         cascades_valid_X, cascades_valid_y,\n",
    "                                                         selected_indices,\n",
    "                                                         music_train, music_predict,\n",
    "                                                         music_confidence, music_score,\n",
    "                                                         train_set_full_model)\n",
    "selected_feature_cost = sum(feature_costs[feature_names[i]] for i in selected_indices)\n",
    "expected_cost = fraction_approximated * selected_feature_cost + \\\n",
    "    (1 - fraction_approximated) * total_feature_cost\n",
    "\n",
    "print(\"Confidence threshold: %5.3f  Percentage of inputs approximated: %5.3f\" \n",
    "      % (threshold, fraction_approximated))\n",
    "print(\"Expected Query Cost = Percent Approximated * Selected Feature Cost +\\n\" +\n",
    "      \"\\t\\t      Percent Not Approximated * Total Feature Cost\")\n",
    "print(\"\\t\\t    = %5.3f * %5.3f + %5.3f * %5.3f = %5.3f\" % \n",
    "      (fraction_approximated, selected_feature_cost,\n",
    "       1 - fraction_approximated, total_feature_cost, expected_cost))\n",
    "print(\"Projected speedup: %5.3f\" % (total_feature_cost / expected_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, cascades are expected to improve performance by 1.75x.  That's not nothing, but it's not great either.  Can we do better?   Earlier, we said we would construct cascades from the best set of features whose cost was less than half the total feature cost.  The choice of half was arbitary--we could just as easily have chosen another value.  Let's try with one quarter the total cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature cost: 19.000  Selected feature cost cutoff: 4.750\n",
      "Selected features:\n",
      "\tuser_latent_features\n",
      "\tuser_cluster_features\n",
      "\tsong_cluster_features\n",
      "\tsns_features\n",
      "Confidence threshold: 0.600  Percentage of inputs approximated: 0.835\n",
      "Expected Query Cost = Percent Approximated * Selected Feature Cost +\n",
      "\t\t      Percent Not Approximated * Total Feature Cost\n",
      "\t\t    = 0.835 * 4.000 + 0.165 * 19.000 = 6.480\n",
      "Projected speedup: 2.932\n"
     ]
    }
   ],
   "source": [
    "total_feature_cost = sum(feature_costs.values())\n",
    "cost_cutoff = 0.25 * total_feature_cost\n",
    "selected_indices = cascades_construct.select_features(feature_costs, feature_importances, cost_cutoff)\n",
    "selected_features = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "print(\"Total feature cost: %5.3f  Selected feature cost cutoff: %5.3f\" % (total_feature_cost, cost_cutoff))\n",
    "print(\"Selected features:\")\n",
    "for feature in selected_features:\n",
    "    print(\"\\t%s\" % feature)\n",
    "\n",
    "threshold, fraction_approximated = \\\n",
    "    cascades_construct.calculate_feature_set_performance(cascades_train_X, cascades_train_y, \n",
    "                                                         cascades_valid_X, cascades_valid_y,\n",
    "                                                         selected_indices,\n",
    "                                                         music_train, music_predict,\n",
    "                                                         music_confidence, music_score,\n",
    "                                                         train_set_full_model)\n",
    "selected_feature_cost = sum(feature_costs[feature_names[i]] for i in selected_indices)\n",
    "expected_cost = fraction_approximated * selected_feature_cost + \\\n",
    "(1 - fraction_approximated) * total_feature_cost\n",
    "print(\"Confidence threshold: %5.3f  Percentage of inputs approximated: %5.3f\" \n",
    "      % (threshold, fraction_approximated))\n",
    "print(\"Expected Query Cost = Percent Approximated * Selected Feature Cost +\\n\" +\n",
    "      \"\\t\\t      Percent Not Approximated * Total Feature Cost\")\n",
    "print(\"\\t\\t    = %5.3f * %5.3f + %5.3f * %5.3f = %5.3f\" % \n",
    "      (fraction_approximated, selected_feature_cost,\n",
    "       1 - fraction_approximated, total_feature_cost, expected_cost))\n",
    "print(\"Projected speedup: %5.3f\" % (total_feature_cost / expected_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're doing better!  We're computing fewer features when using the approximate model, but still approximating most data inputs, so we're seeing a much larger expected performance improvement of almost 3x.  In practice, Willump will experiment with several different cost cutoffs and choose the one that maximizes projected performance improvement.\n",
    "\n",
    "Now, we construct cascades from the features we selected above, training approximate and full models on the entire training set and storing them in a parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades_params = {}\n",
    "cascades_params[\"selected_feature_indices\"] = selected_indices\n",
    "cascades_params[\"cascade_threshold\"] = threshold\n",
    "full_model = music_train(train_y, train_X_features)\n",
    "cascades_params[\"full_model\"] = full_model\n",
    "approximate_model = music_train(train_y, [train_X_features[i] for i in selected_indices])\n",
    "cascades_params[\"approximate_model\"] = approximate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's evaluate how well cascades perform in practice.  Here's the prediction pipeline for this application.  Let's run the pipeline without cascades to see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time 8.805201s\n",
      "AUC Score: 0.749237\n"
     ]
    }
   ],
   "source": [
    "def music_eval_pipeline(input_X, model):\n",
    "    user_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"features_uf\", db=db)\n",
    "    song_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"features_sf\", db=db)\n",
    "    user_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_msno_25\", name=\"uc_features\", db=db)\n",
    "    song_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_song_id_25\", name=\"sc_features\", db=db)\n",
    "    artist_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_artist_name_25\", name=\"ac_features\", db=db)\n",
    "    user_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"us_features\", db=db)\n",
    "    song_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"ss_features\", db=db)\n",
    "    artist_features = get_features_from_redis(\n",
    "        input_X, column=\"artist_name\", name=\"as_features\", db=db)\n",
    "    genre_features = get_features_from_redis(\n",
    "        input_X, column=\"genre_max\", name=\"gs_features\", db=db)\n",
    "    city_features = get_features_from_redis(\n",
    "        input_X, column=\"city\", name=\"cs_features\", db=db)\n",
    "    ages_features = get_features_from_redis(\n",
    "        input_X, column=\"bd\", name=\"ages_features\", db=db)\n",
    "    language_features = get_features_from_redis(\n",
    "        input_X, column=\"language\", name=\"ls_features\", db=db)\n",
    "    gender_features = get_features_from_redis(\n",
    "        input_X, column=\"gender\", name=\"gender_features\", db=db)\n",
    "    composer_features = get_features_from_redis(\n",
    "        input_X, column=\"composer\", name=\"composer_features\", db=db)\n",
    "    lyrs_features = get_features_from_redis(\n",
    "        input_X, column=\"lyricist\", name=\"lyrs_features\", db=db)\n",
    "    sns_features = get_features_from_redis(\n",
    "        input_X, column=\"source_screen_name\", name=\"sns_features\", db=db)\n",
    "    stabs_features = get_features_from_redis(\n",
    "        input_X, column=\"source_system_tab\", name=\"stabs_features\", db=db)\n",
    "    stypes_features = get_features_from_redis(\n",
    "        input_X, column=\"source_type\", name=\"stypes_features\", db=db)\n",
    "    regs_features = get_features_from_redis(\n",
    "        input_X, column=\"registered_via\", name=\"regs_features\", db=db)\n",
    "    return music_predict(model,\n",
    "                       [user_latent_features, song_latent_features, user_cluster_features,\n",
    "                        song_cluster_features, artist_cluster_features, user_features,\n",
    "                        song_features, artist_features, genre_features, city_features,\n",
    "                        ages_features, language_features, gender_features,\n",
    "                        composer_features,lyrs_features, sns_features, stabs_features,\n",
    "                        stypes_features, regs_features])\n",
    "\n",
    "time_start = time.time()\n",
    "preds = music_eval_pipeline(test_X[:2000], full_model)\n",
    "time_elapsed = time.time() - time_start\n",
    "print(\"Elapsed Time %fs\" % time_elapsed)\n",
    "\n",
    "print(\"AUC Score: %f\" % music_score(preds, test_y[:2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use cascades!  Like before, the decorator tells Willump what to do--in this case, optimize the pipeline using the cascades parameters we determined earlier.  We now run the optimized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time 3.220090s\n",
      "AUC Score: 0.750532\n"
     ]
    }
   ],
   "source": [
    "@willump_execute(predict_function=music_predict,\n",
    "                 confidence_function=music_confidence,\n",
    "                 predict_cascades_params=cascades_params)\n",
    "def music_eval_pipeline(input_X, model):\n",
    "    user_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"features_uf\", db=db)\n",
    "    song_latent_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"features_sf\", db=db)\n",
    "    user_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_msno_25\", name=\"uc_features\", db=db)\n",
    "    song_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_song_id_25\", name=\"sc_features\", db=db)\n",
    "    artist_cluster_features = get_features_from_redis(\n",
    "        input_X, column=\"cluster_artist_name_25\", name=\"ac_features\", db=db)\n",
    "    user_features = get_features_from_redis(\n",
    "        input_X, column=\"msno\", name=\"us_features\", db=db)\n",
    "    song_features = get_features_from_redis(\n",
    "        input_X, column=\"song_id\", name=\"ss_features\", db=db)\n",
    "    artist_features = get_features_from_redis(\n",
    "        input_X, column=\"artist_name\", name=\"as_features\", db=db)\n",
    "    genre_features = get_features_from_redis(\n",
    "        input_X, column=\"genre_max\", name=\"gs_features\", db=db)\n",
    "    city_features = get_features_from_redis(\n",
    "        input_X, column=\"city\", name=\"cs_features\", db=db)\n",
    "    ages_features = get_features_from_redis(\n",
    "        input_X, column=\"bd\", name=\"ages_features\", db=db)\n",
    "    language_features = get_features_from_redis(\n",
    "        input_X, column=\"language\", name=\"ls_features\", db=db)\n",
    "    gender_features = get_features_from_redis(\n",
    "        input_X, column=\"gender\", name=\"gender_features\", db=db)\n",
    "    composer_features = get_features_from_redis(\n",
    "        input_X, column=\"composer\", name=\"composer_features\", db=db)\n",
    "    lyrs_features = get_features_from_redis(\n",
    "        input_X, column=\"lyricist\", name=\"lyrs_features\", db=db)\n",
    "    sns_features = get_features_from_redis(\n",
    "        input_X, column=\"source_screen_name\", name=\"sns_features\", db=db)\n",
    "    stabs_features = get_features_from_redis(\n",
    "        input_X, column=\"source_system_tab\", name=\"stabs_features\", db=db)\n",
    "    stypes_features = get_features_from_redis(\n",
    "        input_X, column=\"source_type\", name=\"stypes_features\", db=db)\n",
    "    regs_features = get_features_from_redis(\n",
    "        input_X, column=\"registered_via\", name=\"regs_features\", db=db)\n",
    "    return music_predict(model,\n",
    "                       [user_latent_features, song_latent_features, user_cluster_features,\n",
    "                        song_cluster_features, artist_cluster_features, user_features,\n",
    "                        song_features, artist_features, genre_features, city_features,\n",
    "                        ages_features, language_features, gender_features,\n",
    "                        composer_features,lyrs_features, sns_features, stabs_features,\n",
    "                        stypes_features, regs_features])\n",
    "\n",
    "music_eval_pipeline(test_X.iloc[:100], full_model)\n",
    "music_eval_pipeline(test_X.iloc[:100], full_model)\n",
    "time_start = time.time()\n",
    "preds = music_eval_pipeline(test_X[:2000], full_model)\n",
    "time_elapsed = time.time() - time_start\n",
    "print(\"Elapsed Time %fs\" % time_elapsed)\n",
    "\n",
    "print(\"AUC Score: %f\" % music_score(preds, test_y[:2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  A ~2.8x performance improvement and no loss in accuracy.  This process is fully automatic and model-agnostic once you write your application in the correct format, so you can try it for yourself and see similar gains!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
